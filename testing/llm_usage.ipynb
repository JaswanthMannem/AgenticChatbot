{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700116c3",
   "metadata": {},
   "source": [
    "# langchain and ollama usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861f5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d182f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3dd7cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mountbatten, also known as Louis Mountbatten, was a British statesman, member of the British Royal Family and a naval officer who served as the last Viceroy of India (1947) and the first Governor-General of India (1947–48). He played a crucial role in the Partition of India and independence of Pakistan.\n",
      "\n",
      "Mountbatten was appointed by Winston Churchill in March 1947, with the mandate to oversee the transition from British Raj to Indian self-rule within one year. Under his leadership, India and Pakistan were officially granted independence on August 15, 1947 (India) and August 14, 1947 (Pakistan). Mountbatten was not solely responsible for the division of India and Pakistan but played an instrumental role in facilitating the process.\n",
      "\n",
      "The actual decision to divide India along religious lines (Hindu-majority India and Muslim-majority Pakistan) was made by leaders like Mohammad Ali Jinnah, Jawaharlal Nehru, Mahatma Gandhi, and other members of the Indian National Congress and the Muslim League. However, Mountbatten's presence as Viceroy provided a platform for these negotiations to take place, and he helped steer the process towards a peaceful partition while ensuring a smooth transfer of power in the face of escalating communal tensions between Hindus and Muslims in British India.\n",
      "\n",
      "The violence and displacement that occurred during the Partition is widely regarded as one of the largest mass migrations and humanitarian crises in history, with an estimated 14-15 million people being affected and hundreds of thousands of lives lost.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Who is mount batten. Who played crucial role in dividing india and pakistan\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe715e5c",
   "metadata": {},
   "source": [
    "# langchain with context history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cfd5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, ToolMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "736ede97",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What is the weather in Paris?\"),\n",
    "    AIMessage(content=\"Calling tool: get_weather with location=Paris...\"),\n",
    "    ToolMessage(tool_call_id=\"weather-1\", content=\"The weather in Paris is sunny and 25°C.\"),\n",
    "    HumanMessage(content=\"Should I take an umbrella?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(chat_history)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f7e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the current forecast, you probably won't need an umbrella as it's expected to be sunny in Paris today. However, always good to have one handy if you expect a sudden change or just as a precaution. Enjoy your day!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b4570",
   "metadata": {},
   "source": [
    "# langchain with manual tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9362a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66a0e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(\n",
    "    model=\"mistral\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fc022c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str) -> str:\n",
    "    return f\"The weather in {location} is sunny and 25°C.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0d901ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    SystemMessage(content=\"You are a helpful assistant. If a tool is required we have a get_weather tool for weather forecasting with parameters location. So from you want to extract location name and just give it as output. Example, prompt = 'i want to know weather in hyderabad' response = {'location':'hyderabad'}. I want the response to be in json\"),\n",
    "\n",
    "    HumanMessage(content=\"What's the weather in Paris?\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76944f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\"location\": \"Paris\"}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(chat_history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6b744b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Paris'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = json.loads(response)\n",
    "print(data)  # Output: {'location': 'Paris'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d5f5bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Paris'}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "data = ast.literal_eval(response)\n",
    "print(data)  # Output: {'location': 'Paris'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d39b821e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5883ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in Paris is sunny and 25°C.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather(data[\"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1be0c002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I cannot predict the future. The Indian Premier League (IPL) in 2024 hasn't taken place yet, and it would be speculative to determine who will win at this time.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Who won ipl 2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863dd74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
